{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: MacOSX\n"
     ]
    }
   ],
   "source": [
    "%matplotlib"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# Load files\n",
    "def load_file(path):\n",
    "    return pd.read_csv(path, sep=\";\", header=0, infer_datetime_format=True, parse_dates=['timestamp'], index_col=['timestamp'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# Define dataset to import\n",
    "ignore_ids = [223, 45, 19, 105, 75, 63, 58, 59]\n",
    "directory = \"../data/processed/batiments/\"\n",
    "def get_selected_ids(selection_):\n",
    "    # Get ids\n",
    "    meta = pd.read_csv(directory+\"metadata.csv\", sep=';')\n",
    "    # Use selection\n",
    "    for select_ in selection_:\n",
    "        if select_.startswith(\"max_\"):\n",
    "            if selection_[select_] is not None:\n",
    "                col = select_[4:]\n",
    "                meta = meta[meta[col] <= selection_[select_]]\n",
    "        elif select_.startswith(\"min_\"):\n",
    "            if selection_[select_] is not None:\n",
    "                col = select_[4:]\n",
    "                meta = meta[meta[col] >= selection_[select_]]\n",
    "        elif select_.startswith(\"in_\"):\n",
    "            if selection_[select_]:\n",
    "                col = select_[3:]\n",
    "                meta = meta[meta[col].isin(selection_[select_])]\n",
    "        else:\n",
    "            col = select_\n",
    "            meta = meta[meta[col] == selection_[col]]\n",
    "    # Remove manual ids\n",
    "    meta = meta[~meta[\"bat_id\"].isin(ignore_ids)]\n",
    "    ids_ = meta[\"bat_id\"].values\n",
    "    return ids_\n",
    "\n",
    "def get_list_of_datasets(ids_):\n",
    "    list_of_datasets_ = []\n",
    "    list_of_ids_ = []\n",
    "    for filename_ in os.listdir(directory):\n",
    "        if re.fullmatch(\"^[0-9]+.csv\", filename_) and int(filename_[:filename_.find('.')]) in ids_:\n",
    "            list_of_datasets_.append(load_file(directory+filename_))\n",
    "            list_of_ids_.append(int(filename_[:filename_.find('.')]))\n",
    "    return list_of_datasets_, list_of_ids_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Les ids suivants ont été définis manuellement après affichage de tous les datasets, ils pourront donc être exclus lorsque nécessaire\n",
    "\n",
    "En fonction du pas de temps\n",
    "- 15\n",
    "    - à traiter\n",
    "        - 173, 89, 149, 298, 115, 261, 287, 119, 108, 109, 232, 190, 41, 6\n",
    "    - bizarres\n",
    "        - 204, 11, 302, 33, 34, 233, 92, 191, 46, 221, 194, 5, 197, 141, 237\n",
    "    - courts\n",
    "        - 65, 205, 238, 48, 305, 11, 246, 34, 257, 23, 44, 225, 194, 5, 43, 142\n",
    "- 60\n",
    "    - à traiter\n",
    "        - 198, 199, 60, 100, 16, 27, 26, 134, 20, 93, 186, 152, 53, 185, 253, 209, 96\n",
    "    - bizarres\n",
    "        - 98, 77, 203, 259, 112, 39, 117, 250, 297, 192, 195, 234, 196\n",
    "    - courts\n",
    "        - 159, 239, 177, 264, 266, 263, 288, 101, 278, 251, 297, 192, 51, 224, 85, 236, 196\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# name of the column with the value to match or put min_, max_ or in_ before the column name to make a condition\n",
    "selection = {'time_step': 60,\n",
    "             'min_bat_id': None,\n",
    "             'max_bat_id': None,\n",
    "             'in_bat_id': []}\n",
    "\n",
    "_ignore_60_ids = [198, 199, 60, 100, 16, 27, 26, 134, 20, 93, 186, 152, 53, 185, 253, 209, 96,\n",
    "                  98, 77, 203, 259, 112, 39, 117, 250, 297, 192, 195, 234, 196,\n",
    "                  159, 239, 177, 264, 266, 263, 288, 101, 278, 251, 297, 192, 51, 224, 85, 236, 196]\n",
    "\n",
    "_ignore_15_ids = [173, 89, 149, 298, 115, 261, 287, 119, 108, 109, 232, 190, 41, 6,\n",
    "                  204, 11, 302, 33, 34, 233, 92, 191, 46, 221, 194, 5, 197, 141, 237,\n",
    "                  65, 205, 238, 48, 305, 11, 246, 34, 257, 23, 44, 225, 194, 5, 43, 142]\n",
    "\n",
    "ids = get_selected_ids(selection)\n",
    "\n",
    "# If you want to ignore certain ids uncomment next line\n",
    "#ids = [id_ for id_ in ids if id_ not in _ignore_60_ids]\n",
    "\n",
    "list_of_datasets, list_of_ids = get_list_of_datasets(ids)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [],
   "source": [
    "# Return last full week that goes monday to sunday\n",
    "def get_last_full_week(df, step):\n",
    "    last_df_date = df.index[-1]\n",
    "    day_delta = last_df_date.isoweekday() - 1\n",
    "    minutes_delta = last_df_date.hour * 60 + last_df_date.minute\n",
    "    end_selection_date = last_df_date - pd.Timedelta(days=day_delta, minutes=minutes_delta)\n",
    "    #start_selection_date = end_selection_date - pd.Timedelta(days=7)\n",
    "\n",
    "    selection_ =  df[df.index < end_selection_date]\n",
    "    selection_ = df.iloc[-7*24*60//step:]\n",
    "\n",
    "    return selection_\n",
    "\n",
    "# Return last full year 1 jan to 31 dec\n",
    "def get_last_full_year(df, step):\n",
    "    selection_year = df.index[-1].year -1\n",
    "    selection_ = df[df.index.year <= selection_year]\n",
    "    dim = 365*24*60//step\n",
    "    selection_ = df.iloc[-dim:]\n",
    "    if len(selection_) != dim:\n",
    "        return pd.DataFrame()\n",
    "    return  selection_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "# get values of the length for each dataset for the time_step given\n",
    "time_step = \"week\"\n",
    "\n",
    "scalers = []\n",
    "values = []\n",
    "datasets_used = []\n",
    "for i, dataset_ in enumerate(list_of_datasets):\n",
    "    if time_step == \"week\":\n",
    "        df = get_last_full_week(dataset_, selection['time_step'])\n",
    "    elif time_step == \"year\":\n",
    "        df = get_last_full_year(dataset_, selection['time_step'])\n",
    "    else:\n",
    "        raise Exception(\"time_step is not 'week' or 'year' but {} instead\".format(time_step))\n",
    "    if not df.empty:\n",
    "        week_values = df['active_power'].values\n",
    "        datasets_used.append(i)\n",
    "        scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "        scaled_week_values = scaler.fit_transform(week_values.reshape((week_values.shape[0], 1))).flatten()\n",
    "        scalers.append(scaler)\n",
    "        values.append(scaled_week_values)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [],
   "source": [
    "# Run clustering\n",
    "n_clusters = 8\n",
    "kmeans = KMeans(n_clusters=n_clusters).fit(values)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [],
   "source": [
    "# Get a list of ids for each cluster\n",
    "clusters_ids = [[] for _ in range(n_clusters)]\n",
    "for n in range(n_clusters):\n",
    "    for i, label in enumerate(kmeans.labels_):\n",
    "        if label == n:\n",
    "            clusters_ids[n].append(list_of_ids[datasets_used[i]])\n",
    "            # Uncomment next two lines to plot every dataset\n",
    "            #plt.figure(\"{} - id:{}\".format(n, list_of_ids[datasets_used[i]]))\n",
    "            #plt.plot(values[i])\n",
    "print(clusters_ids)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}